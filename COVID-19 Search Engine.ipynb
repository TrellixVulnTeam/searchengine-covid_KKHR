{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "loose-storage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maximum number of articles you want returned for each query\n",
    "TOP_N_ARTICLES = 5\n",
    "\n",
    "# maximum number of points/sentences you want returned for each article summary \n",
    "TOP_N_POINTS = 5\n",
    "import time\n",
    "import re\n",
    "import json\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from collections import Counter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "golden-sheep",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_match(text, keywords):\n",
    "    '''Check if any `keywords` exist in `text`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    text : str\n",
    "    keywords : List[str]\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bool\n",
    "    '''\n",
    "    return any(f'{keyterm} ' in text.lower() for keyterm in keywords)\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    '''Remove punctuation from query and lowercase letters.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    query : str\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "    '''\n",
    "    return re.sub('\\?|!|\\.|,|\\(|\\)', '', text).lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "electoral-organic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_corpus():\n",
    "    '''Get corpus data.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "    '''\n",
    "    data = pd.read_csv(ARTICLE_INFO_PATH).loc[:, 'text']\n",
    "    corpus_text = ' '.join(data.values)\n",
    "    return corpus_text.replace(\"\\n\", \" \")\n",
    "\n",
    "\n",
    "def get_stopwords_from_corpus(corpus):\n",
    "    '''Extract stopwords from corpus based on word frequency.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    corpus : str\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    List[str]\n",
    "    '''\n",
    "    sample = corpus.lower().split(' ')\n",
    "\n",
    "    word_counts = Counter(sample)\n",
    "\n",
    "    max_word_count = max(word_counts.values())\n",
    "\n",
    "    threshold = 5000\n",
    "    return [word for word, count in word_counts.items() if count > threshold]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "naked-conservative",
   "metadata": {},
   "outputs": [],
   "source": [
    "CORPUS_STOPWORDS = [\n",
    "    'number',\n",
    "    'human',\n",
    "    'cases',\n",
    "    'also',\n",
    "    'reported',\n",
    "    'one',\n",
    "    'immune',\n",
    "    'response',\n",
    "    'within',\n",
    "    'influenza',\n",
    "    'among',\n",
    "    'different',\n",
    "    'high',\n",
    "    'found',\n",
    "    'showed',\n",
    "    'use',\n",
    "    'identified',\n",
    "    'two',\n",
    "    'used',\n",
    "    'results',\n",
    "    'analysis',\n",
    "    'performed',\n",
    "    'using',\n",
    "    'described',\n",
    "    'detected',\n",
    "    'including',\n",
    "    'group',\n",
    "    'could',\n",
    "    'observed',\n",
    "    'significant',\n",
    "    'based',\n",
    "    'shown',\n",
    "    'however,',\n",
    "    'compared',\n",
    "    'higher',\n",
    "    'may',\n",
    "    'specific',\n",
    "    'studies',\n",
    "    'study',\n",
    "    'type',\n",
    "    'well',\n",
    "    'although',\n",
    "    'levels',\n",
    "    'host',\n",
    "    'activity',\n",
    "    'data',\n",
    "    'associated',\n",
    "    'due',\n",
    "    'samples',\n",
    "    'figure',\n",
    "    'table',\n",
    "    'case',\n",
    "    'effect', \n",
    "    'effects', \n",
    "    'affected',\n",
    "    'across',\n",
    "    'within',\n",
    "    'humans',\n",
    "    'who',\n",
    "    'what',\n",
    "    'why',\n",
    "    'how',\n",
    "    'distribution',\n",
    "    'eg',\n",
    "    'ie',\n",
    "    'prevalence',\n",
    "    'particularly',\n",
    "    'whether',\n",
    "    'make',\n",
    "    'even',\n",
    "    'might',\n",
    "    '2019',\n",
    "]\n",
    "COVID_19_TERMS = [\n",
    "    'covid-19', \n",
    "    'covid 19',\n",
    "    'covid-2019',\n",
    "    '2019 novel coronavirus', \n",
    "    'corona virus disease 2019',\n",
    "    'coronavirus disease 19',\n",
    "    'coronavirus 2019',\n",
    "    '2019-ncov',\n",
    "    'ncov-2019', \n",
    "    'wuhan virus',\n",
    "    'wuhan coronavirus',\n",
    "    'wuhan pneumonia',\n",
    "    'NCIP',\n",
    "    'sars-cov-2',\n",
    "    'sars-cov2',\n",
    "]\n",
    "\n",
    "VIRUS_TERMS = [\n",
    "    'epidemic', \n",
    "    'pandemic', \n",
    "    'viral',\n",
    "    'virus',\n",
    "    'viruses',\n",
    "    'coronavirus', \n",
    "    'respiratory',\n",
    "    'infectious',\n",
    "] + COVID_19_TERMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "wanted-hostel",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "    \n",
    "\n",
    "def get_stopwords():\n",
    "    '''Get english stopwords and corpus stopwords.''' \n",
    "    return set(VIRUS_TERMS + CORPUS_STOPWORDS + stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "treated-graduate",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# url links, 'doi preprint', [citations]\n",
    "ARTIFACTS = r'https?:\\/\\/.[^\\s\\\\]*|doi: medRxiv|preprint|\\[\\d+\\]|\\[\\d+\\, \\d+\\]'\n",
    "\n",
    "\n",
    "class Article():\n",
    "    '''`Article` object for storing article text information.'''\n",
    "\n",
    "    def __init__(self, article):\n",
    "        '''Initialize `Article` object.'''\n",
    "        self.article = article\n",
    "        \n",
    "    def get_title(self):\n",
    "        '''Article title.'''\n",
    "        return self.article['metadata']['title']\n",
    "    \n",
    "    def get_abstract(self):\n",
    "        '''Article abstract bodytext.'''\n",
    "        return self.clean_text_of_artifacts(\n",
    "            self.combine_bodytext(self.article.get('abstract', []))\n",
    "        )\n",
    "\n",
    "    def get_bodytext(self):\n",
    "        '''Article main text.'''\n",
    "        return self.clean_text_of_artifacts(\n",
    "            self.combine_bodytext(self.article.get('body_text', []))\n",
    "        )\n",
    "\n",
    "    def get_full_text(self):\n",
    "        '''Article abstract and body text.'''\n",
    "        return self.get_abstract() + ' ' + self.get_bodytext()\n",
    "    \n",
    "    @staticmethod\n",
    "    def clean_text_of_artifacts(text):\n",
    "        '''Remove URL links and other artifacts from text.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        text : str\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        str\n",
    "        '''\n",
    "        return re.sub(ARTIFACTS, '', text, flags=re.MULTILINE)\n",
    "\n",
    "    @staticmethod\n",
    "    def combine_bodytext(text_info):\n",
    "        '''Get combined text fields from list of dicts.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        text_info : List[Dict[str]]\n",
    "            List of body text.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        str\n",
    "            `text_info` joined together into string.\n",
    "        '''\n",
    "        return ' '.join(x['text'] for x in text_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "deluxe-administration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 0.01 minutes\n"
     ]
    }
   ],
   "source": [
    "def filter_covid19_articles(df):\n",
    "    '''Filter DataFrame on articles that contain COVID-19 keyterms.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        Article info, including 'text' column.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        Article info of COVID-19 related papers.\n",
    "    '''\n",
    "    return df[\n",
    "        df['text'].apply(lambda x: is_match(x, set(COVID_19_TERMS)))\n",
    "    ]\n",
    "\n",
    "\n",
    "def tokenize_documents(corpus):\n",
    "    '''Tokenize corpus of documents.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    corpus : List[str]\n",
    "        Corpus of research paper documents.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    List[List[str]]\n",
    "        documents --> words\n",
    "    '''\n",
    "    return [\n",
    "        [\n",
    "            word for word in word_tokenize(clean_text(doc)) \n",
    "            if word not in get_stopwords()\n",
    "        ] for doc in corpus \n",
    "    ] \n",
    "\n",
    "def load_model(filename):\n",
    "    '''Load pickled model.'''\n",
    "    return pickle.load(open(filename, 'rb'))\n",
    "\n",
    "def train_bm25_model(corpus):\n",
    "    '''Train an Okapi BM25 model on corpus of research articles.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    corpus : pandas.Series\n",
    "\n",
    "    Returns \n",
    "    -------\n",
    "    rankbm25.BM25Okapi\n",
    "        Okapi BM25 model trained on corpus data.\n",
    "    '''    \n",
    "    logging.info('Tokenizing documents...')\n",
    "    tokenized_corpus = tokenize_documents(corpus)\n",
    "        \n",
    "    logging.info('Training BM25 model...')\n",
    "    return BM25Okapi(tokenized_corpus)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# main()\n",
    "bm25_model = load_model(\"E:\\\\COVID-app\\\\bm25_model\")\n",
    "    \n",
    "seconds = time.time() - start_time\n",
    "minutes = seconds / 60\n",
    "print('Took {:.2f} minutes'.format(minutes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "seven-governor",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors, Word2Vec \n",
    "\n",
    "class SearchQuery():\n",
    "    '''`SearchQuery` object for cleaning and processing a `query` input.'''\n",
    "\n",
    "    SIMILARITY_THRESHOLD = 0.62\n",
    "\n",
    "    def __init__(self, query):\n",
    "        '''Initialize `SearchQuery` object.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        query : str\n",
    "        '''\n",
    "        self.query = clean_text(query)\n",
    "        self.init_query_keywords()\n",
    "        self.init_related_keywords(self.get_word2vec_model())\n",
    "\n",
    "    def init_query_keywords(self):\n",
    "        '''Initialize query keywords.'''\n",
    "        self.query_keywords = [\n",
    "            x for x in self.query.split() if x not in get_stopwords()\n",
    "        ]\n",
    "\n",
    "    def init_related_keywords(self, word2vec_model):\n",
    "        '''Initialize keywords related to `query_keywords`.\n",
    "\n",
    "        Iterates over each keyterm in `query_keywords` and finds related words \n",
    "        from the trained `Word2Vec` vocabulary. If there's a high enough \n",
    "        similarity score, adds it to `related_keywords`.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        word2vec_model : gensim.models.Word2Vec\n",
    "            `Word2Vec` model trained on corpus data.  \n",
    "        '''\n",
    "        self.related_keywords = []\n",
    "        for word in self.query_keywords:\n",
    "            if word in word2vec_model.wv.vocab:\n",
    "                self.related_keywords += [\n",
    "                    x[0] for x in word2vec_model.wv.most_similar(word, topn=10) \n",
    "                    if x[1] > SearchQuery.SIMILARITY_THRESHOLD\n",
    "                ]\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_word2vec_model():\n",
    "        '''Load `Word2Vec` model previously trained on the dataset.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        gensim.models.Word2Vec\n",
    "        '''\n",
    "        return Word2Vec.load(\"E:\\\\COVID-app\\\\word2vec_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "rapid-stomach",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "from gensim.summarization.summarizer import summarize\n",
    "\n",
    "\n",
    "class Summary():\n",
    "    '''`Summary` object for extracting executive summary from text.'''\n",
    "    \n",
    "    def __init__(self, text, query_keywords):\n",
    "        '''Initialize `Summary` object.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        text : str\n",
    "        query_keywords : List[str]\n",
    "        '''\n",
    "        self.text = text\n",
    "        self.keywords = query_keywords\n",
    "\n",
    "    def get_topn_sentences(self):\n",
    "        '''Get top `n` sentences of text as summary.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        List[str]\n",
    "        '''\n",
    "        ranked_sentences = summarize(self.text, split=True) \n",
    "        relevant_sentences = self.filter_relevant_sentences(ranked_sentences)\n",
    "\n",
    "        return relevant_sentences[:TOP_N_POINTS]\n",
    "    \n",
    "    @staticmethod\n",
    "    def is_decimal_value_in_text(text):\n",
    "        '''Check if there is a decimal value or percentage within the text.\n",
    "\n",
    "        Make sure that decimal value is not a Figure or Section number.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        text : str\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        bool\n",
    "        '''\n",
    "        patterns = [\n",
    "            r'(?<!Section )([0-9]+\\.[0-9]+|%)',\n",
    "            r'(?<!SECTION )([0-9]+\\.[0-9]+|%)',\n",
    "            r'(?<!Figure )([0-9]+\\.[0-9]+|%)',\n",
    "            r'(?<!FIGURE )([0-9]+\\.[0-9]+|%)',\n",
    "            r'(?<!Fig )([0-9]+\\.[0-9]+|%)',\n",
    "            r'(?<!Fig. )([0-9]+\\.[0-9]+|%)',\n",
    "            r'(?<!Tables )([0-9]+\\.[0-9]+|%)',\n",
    "            r'(?<!Chapter )([0-9]+\\.[0-9]+|%)',\n",
    "            r'(?<!CHAPTER )([0-9]+\\.[0-9]+|%)',\n",
    "        ]\n",
    "\n",
    "        if all(re.search(pattern, text) for pattern in patterns):\n",
    "            return True \n",
    "        \n",
    "        return False\n",
    "    def filter_relevant_sentences(self, sentences):\n",
    "        '''Filter sentences on relevancy filter. \n",
    "        \n",
    "        If filters out all sentences, returns original unfiltered sentences instead.\n",
    "        \n",
    "        NOTE: Previously was filtering on whether keyword exists in sentence. Now\n",
    "        filters on whether decimal value exists in sentence.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        sentences : List[str]\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        List[str]\n",
    "        '''\n",
    "        filtered_sentences = [\n",
    "            sentence for sentence in sentences \n",
    "            if self.is_decimal_value_in_text(sentence)\n",
    "        ]\n",
    "        \n",
    "        if not filtered_sentences:\n",
    "            return sentences\n",
    "        \n",
    "        return filtered_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "experienced-martial",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SearchResult():\n",
    "    '''`SearchResult` object for storing search result article information.'''\n",
    "\n",
    "    def __init__(self, title, text, url, query_keywords):\n",
    "        '''Initialize `SearchResult` object.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        title : str\n",
    "            Article title.\n",
    "        text : str\n",
    "            Article text.\n",
    "        url : str\n",
    "            Article url link.\n",
    "        query_keywords: List[str]\n",
    "            Query search keywords.\n",
    "        '''\n",
    "        self.title = title\n",
    "        self.text = text\n",
    "        self.url = url\n",
    "        self.keywords = query_keywords \n",
    "\n",
    "        self.main_points = self.get_topn_points()\n",
    "\n",
    "        if isinstance(title, str):\n",
    "            text = text + title\n",
    "        \n",
    "        self.study_info = StudyInfo(text, url)\n",
    "    \n",
    "    def get_topn_points(self):\n",
    "        '''Keep `n` most highly ranked article points.'''\n",
    "        points = Summary(self.text, self.keywords)\n",
    "        \n",
    "        return points.get_topn_sentences()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "current-junior",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StudyInfo():\n",
    "    '''Object for extracting the level of evidence for findings in paper.'''\n",
    "\n",
    "    def __init__(self, article_text, url_link):\n",
    "        '''Initialize `StudyInfo` object.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        article_text : str\n",
    "        url_link : str\n",
    "        '''\n",
    "        self.article_text = article_text\n",
    "        self.url = url_link\n",
    "        self.peer_reviewed = self.is_peer_reviewed(article_text)\n",
    "        self.num_studies = self.extract_number_of_studies(article_text)\n",
    "        self.sample_size = self.extract_sample_size(article_text)\n",
    "        self.study_designs = self.extract_study_design(article_text) \n",
    "\n",
    "    @staticmethod\n",
    "    def is_peer_reviewed(text):\n",
    "        '''Check if paper is peer-reviewed.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Optional[bool]\n",
    "            Returns None if unsure.\n",
    "        '''\n",
    "        non_peer_reviewed_clause = 'was not peer-reviewed'\n",
    "\n",
    "        # \"PMC does not include any non peer-reviewed research articles.\"\n",
    "        peer_review_terms = {\n",
    "            'peer-reviewed', \n",
    "            'peer reviewed', \n",
    "            'peer review', \n",
    "            'pubmed', \n",
    "            'ncbi', \n",
    "            'pmc',\n",
    "        }\n",
    "        if non_peer_reviewed_clause in text:\n",
    "            return False\n",
    "        elif is_match(text, peer_review_terms):\n",
    "            return True\n",
    "\n",
    "        return None\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_number_of_studies(text):\n",
    "        '''Extract the number of studies performed in article research.\n",
    "\n",
    "        Does so by searching for the term 'studies' and returning the numeric \n",
    "        value right before it.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        text : str\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Optional[int]\n",
    "            Returns None if no match found.\n",
    "        '''\n",
    "        pattern = r'(?:([0-9])[a-zA-Z ]{0,5}(?:studies))'\n",
    "\n",
    "        m = re.search(pattern, text)\n",
    "        if m:\n",
    "            return int(m.group(1))\n",
    "    \n",
    "    @staticmethod\n",
    "    def extract_sample_size(text):\n",
    "        '''Extract the sample size of the article research.\n",
    "\n",
    "        Does so by searching for the term 'sample size of' and returning the \n",
    "        numeric value right after it.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        text : str\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Optional[int]\n",
    "            Returns None if no match found.\n",
    "        '''\n",
    "        pattern1 = r'(?:total sample size of( about| over)?)(.[0-9,]+)'\n",
    "        pattern2 = r'(?:sample size of( about| over)?)(.[0-9,]+)'\n",
    "        pattern3 = r'(.[0-9,]+)(.{,14})(?: patients| participants)'\n",
    "\n",
    "        m1 = re.search(pattern1, text)\n",
    "        m2 = re.search(pattern2, text)\n",
    "        m3 = re.search(pattern3, text)\n",
    "        value = None\n",
    "        if m1:\n",
    "            value = m1.group(2).replace(',', '')\n",
    "        elif m2:\n",
    "            value = m2.group(2).replace(',', '')\n",
    "        elif m3:\n",
    "            value = m3.group(1).replace(',', '')\n",
    "\n",
    "        # 'SARS-2 patients' returns -2\n",
    "        # 'COVID-19 patients' returns -19\n",
    "        # added to prevent this\n",
    "        if value:\n",
    "            try:\n",
    "                if int(value) > 0:\n",
    "                    return int(value)\n",
    "            except:\n",
    "                return None\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_study_design(text):\n",
    "        \n",
    "        '''Extracts the type of study design in paper.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        text : str\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        List[str]\n",
    "        '''\n",
    "        study_designs = [\n",
    "            'case control',\n",
    "            'case study',\n",
    "            'cross sectional',\n",
    "            'cross-sectional',\n",
    "            'descriptive study',\n",
    "            'ecological regression',\n",
    "            'experimental study',\n",
    "            'meta-analysis',\n",
    "            'non-randomized',\n",
    "            'non-randomized experimental study',\n",
    "            'observational study',\n",
    "            'prospective case-control',\n",
    "            'prospective cohort',\n",
    "            'prospective study',\n",
    "            'randomized',\n",
    "            'randomized experimental study',\n",
    "            'retrospective cohort',\n",
    "            'retrospective study',\n",
    "            'simulation', \n",
    "            'systematic review',\n",
    "            'time series analysis',    \n",
    "        ]\n",
    "        \n",
    "        return [design for design in study_designs if design in text]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "assisted-intro",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResultsHTMLText():\n",
    "    '''Object for storing search results in HTML text template format.''' \n",
    "\n",
    "    SPACES = '&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp;'\n",
    "    ARTICLE_LINK_HEADER = '<a href=\"{}\"> <i>{}</i></a><br>'\n",
    "    ARTICLE_HEADER = '<i>{}</i> <br>'\n",
    "\n",
    "    HIGHLIGHT = '<span style=\"background-color:#FFB6C1\">{}</span>'\n",
    "\n",
    "    def __init__(self, results_info):\n",
    "        '''Initizialize `ResrultsHTMLText` object.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        results_info : List[SearchResult]\n",
    "        '''\n",
    "        self.results = results_info\n",
    "        self.results_text = ''\n",
    "\n",
    "    def print_peer_review_status(self, peer_reviewed):\n",
    "        '''Add information to on whether the paper had been peer-reviewed.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        peer_reviewed : bool\n",
    "        '''\n",
    "        if peer_reviewed:\n",
    "            self.results_text += (\n",
    "                '&#9830; This paper has been peer-reviewed.<br>'\n",
    "            )\n",
    "        elif peer_reviewed is False:\n",
    "            self.results_text += (\n",
    "                '&#9830; This paper has NOT been peer-reviewed.<br>'\n",
    "            )\n",
    "\n",
    "    def print_num_studies_info(self, num_studies):\n",
    "        '''Add information on the number of studies in the research.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        num_studies : Union[int, str]\n",
    "        '''\n",
    "        if num_studies:\n",
    "            self.results_text += (\n",
    "                f'&#9830; number of studies: {num_studies}<br>'\n",
    "            )\n",
    "    \n",
    "    def print_sample_size_info(self, sample_size):\n",
    "        '''Add information on the sample size of the paper study.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        sample_size : Union[int, str]\n",
    "        '''\n",
    "        if sample_size:\n",
    "            self.results_text += f'&#9830; sample size: {sample_size}<br>'\n",
    "\n",
    "    def print_study_design_info(self, design):\n",
    "        '''Add information of the study design type.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        design : List[str]\n",
    "        '''\n",
    "        if design:\n",
    "            self.results_text += (\n",
    "                f\"&#9830; study design: {', '.join(design)}<br>\"\n",
    "            )\n",
    "            \n",
    "    def get_results_text(self):\n",
    "        '''Get results in HTML template format.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        str\n",
    "        '''\n",
    "        if not self.results:\n",
    "            return self.get_no_search_results_found_text()\n",
    "\n",
    "        self.results_text += '<br>'\n",
    "        for result in self.results:\n",
    "            if result.main_points:  \n",
    "                if isinstance(result.title, float):\n",
    "                    result.title = 'Title Unknown'\n",
    "\n",
    "                if isinstance(result.url, float):\n",
    "                    self.results_text += self.ARTICLE_HEADER.format(\n",
    "                        result.title\n",
    "                    )\n",
    "                else:\n",
    "                    self.results_text += self.ARTICLE_LINK_HEADER.format(\n",
    "                        result.url, result.title\n",
    "                    )\n",
    "                \n",
    "                info = result.study_info\n",
    "                self.print_peer_review_status(info.peer_reviewed)\n",
    "                # self.print_num_studies_info(info.num_studies)\n",
    "                self.print_sample_size_info(info.sample_size)\n",
    "                self.print_study_design_info(info.study_designs)\n",
    "                self.add_article_mainpoints_text(result) \n",
    "                self.results_text += '<br>'    \n",
    "\n",
    "        return self.results_text\n",
    "    def add_article_mainpoints_text(self, result):\n",
    "        '''Return text of main points within the article, in bullet format.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        search_result : SearchResult\n",
    "        '''\n",
    "        self.results_text += '<p>'\n",
    "        for point in result.main_points:    \n",
    "            words = [\n",
    "                ResultsHTMLText.HIGHLIGHT.format(word) \n",
    "                if word.replace(',', '') in result.keywords else word \n",
    "                for word in point.split()\n",
    "            ]\n",
    "\n",
    "            point = ' '.join(words)\n",
    "            self.results_text += '{} -- {} <br><br>'.format(self.SPACES, point)\n",
    "    \n",
    "        self.results_text += '</p>'\n",
    "\n",
    "    def get_no_search_results_found_text(self):\n",
    "        '''Return text informing user no results were found.'''\n",
    "        return (\n",
    "            'No results found -- It appears not a lot of scientific research '\n",
    "            'has been done in this area.'\n",
    "        )\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "blond-uzbekistan",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResultsDataFrame():\n",
    "    '''Object for storing search results as pandas.DataFrame.''' \n",
    "\n",
    "    SPACES = '&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp;'\n",
    "    ARTICLE_LINK_HEADER = '<a href=\"{}\"> <i>{}</i></a><br>'\n",
    "    ARTICLE_HEADER = '<i>{}</i> <br>'\n",
    "\n",
    "    HIGHLIGHT = '<span style=\"background-color:#FFB6C1\">{}</span>'\n",
    "\n",
    "    COLS = [\n",
    "        'Title', 'Article is peer reviewed', 'Sample size of Article', 'Study Design', 'Main Points'\n",
    "    ]\n",
    "    \n",
    "    def __init__(self, results_info):\n",
    "        '''Initizialize `ResrultsHTMLText` object.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        results_info : List[SearchResult]\n",
    "        '''\n",
    "        self.results = results_info\n",
    "        self.results_df = pd.DataFrame(columns=self.COLS)\n",
    "        \n",
    "    def get_results_df(self):\n",
    "        '''Get results in pandas.DataFrame.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pandas.DataFrame\n",
    "        '''\n",
    "        \n",
    "        for result in self.results:\n",
    "            \n",
    "            row = []\n",
    "            if result.main_points:  \n",
    "                if isinstance(result.title, float):\n",
    "                    result.title = 'Title Unknown'\n",
    "\n",
    "                if isinstance(result.url, float):\n",
    "                    row.append(self.ARTICLE_HEADER.format(result.title))\n",
    "                else:\n",
    "                    row.append(\n",
    "                        self.ARTICLE_LINK_HEADER.format(\n",
    "                                result.url, result.title\n",
    "                        )\n",
    "                    )\n",
    "                \n",
    "                info = result.study_info\n",
    "                row.append(info.peer_reviewed)\n",
    "                # row.append(info.num_studies)\n",
    "                row.append(info.sample_size)\n",
    "                row.append(', '.join(info.study_designs))\n",
    "                row.append(self.get_article_mainpoints_text(result))\n",
    "            \n",
    "            row_df = pd.DataFrame([row], columns=self.COLS)\n",
    "            self.results_df = pd.concat([self.results_df, row_df], ignore_index=True)\n",
    "\n",
    "        return self.results_df\n",
    "    \n",
    "    def get_article_mainpoints_text(self, result):\n",
    "        '''Return text of main points within the article, in bullet format.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        search_result : SearchResult\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        str\n",
    "        '''\n",
    "        text = ''\n",
    "        for point in result.main_points:    \n",
    "            words = [\n",
    "                self.HIGHLIGHT.format(word) \n",
    "                # if word.replace(',', '') in result.keywords else word \n",
    "                if Summary.is_decimal_value_in_text(word) else word\n",
    "                for word in point.split()\n",
    "            ]\n",
    "\n",
    "            point = ' '.join(words)\n",
    "            text += '{} -- {} <br><br>'.format(self.SPACES, point)\n",
    "            \n",
    "        return text\n",
    "\n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "acknowledged-community",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "SEARCH_SCORE_THRESHOLD = 10\n",
    "\n",
    "\n",
    "def get_n(bm25_model, keywords):\n",
    "    '''Get number of articles that pass threshold.\n",
    "\n",
    "    NOTE: counts only the articles in the `TOP_N_ARTICLES`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    bm25_model : rank_bm25.BM25Okapi\n",
    "        Ranking/scoring model trained on corpus dataset.\n",
    "    keywords : List[str]\n",
    "        Search query keywords.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        Number of similarity scores of `top_n` articles that pass threshold.\n",
    "    '''\n",
    "    return len(\n",
    "        [score for score in sorted(\n",
    "            bm25_model.get_scores(keywords), reverse=True\n",
    "        )[:TOP_N_ARTICLES] if score > SEARCH_SCORE_THRESHOLD]\n",
    "    )\n",
    "\n",
    "def get_search_results(search):\n",
    "    \n",
    "    global data\n",
    "    global num_pass_threshold\n",
    "    global all_keywords\n",
    "    \n",
    "    '''Get search results of search query.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    search : SearchQuery\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    List[SearchResult]\n",
    "    '''\n",
    "    data = pd.read_csv(\"E:\\\\COVID-app\\\\article_info.csv\")\n",
    "    \n",
    "    all_keywords = search.query_keywords + search.related_keywords\n",
    "    \n",
    "    bm25_model = load_model(\"E:\\\\COVID-app\\\\bm25_model\")\n",
    "    num_pass_threshold = get_n(bm25_model, all_keywords)\n",
    "\n",
    "    if num_pass_threshold == 0:\n",
    "        return []\n",
    "    else:\n",
    "        if num_pass_threshold != 0:\n",
    "\n",
    "            results_text = bm25_model.get_top_n(\n",
    "                all_keywords, data['text'], n = num_pass_threshold\n",
    "            )\n",
    "            results_title = bm25_model.get_top_n(\n",
    "                all_keywords, data['title_meta'], n =num_pass_threshold\n",
    "            )\n",
    "\n",
    "            results_url = bm25_model.get_top_n(\n",
    "                all_keywords, data['url'], n =num_pass_threshold\n",
    "            )\n",
    "\n",
    "            return [\n",
    "                SearchResult(\n",
    "                    title, text, url, all_keywords\n",
    "                ) for title, text, url in zip(results_title, results_text, results_url)\n",
    "            ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "essential-thinking",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_query_results(query):\n",
    "    '''Get results of search query.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    query : str\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    ResultsHTMLText\n",
    "    '''\n",
    "    \n",
    "    global keywords\n",
    "    global results\n",
    "    \n",
    "    search_query = SearchQuery(query)\n",
    "    \n",
    "    keywords = search_query.query_keywords + search_query.related_keywords\n",
    "    display(HTML(f'<h3>Search Terms: {\", \".join(keywords)}</h3>'))\n",
    "\n",
    "    results = get_search_results(search_query)\n",
    "    # return ResultsHTMLText(results).get_results_text()\n",
    "    return ResultsDataFrame(results).get_results_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "planned-stephen",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "def print_answers(queries):\n",
    "    '''Print search results to each query.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    tasks : List[str]\n",
    "    '''\n",
    "    for query in queries:\n",
    "        display(HTML(f'<h2>{query} \\n</h2>'))\n",
    "        final_result = get_query_results(query)\n",
    "        #return final_result\n",
    "        display(HTML(final_result))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "broad-journal",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResultsDataFrame():\n",
    "    '''Object for storing search results as pandas.DataFrame.''' \n",
    "\n",
    "    SPACES = '&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp;'\n",
    "    ARTICLE_LINK_HEADER = '<a href=\"{}\"> <i>{}</i></a><br>'\n",
    "    ARTICLE_HEADER = '<i>{}</i> <br>'\n",
    "\n",
    "    HIGHLIGHT = '<span style=\"background-color:#FFB6C1\">{}</span>'\n",
    "\n",
    "    COLS = [\n",
    "        'Title', 'Article is peer reviewed', 'Sample size of Article', 'Study Design', 'Main Points'\n",
    "    ]\n",
    "    \n",
    "    def __init__(self, results_info):\n",
    "        '''Initizialize `ResrultsHTMLText` object.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        results_info : List[SearchResult]\n",
    "        '''\n",
    "        self.results = results_info\n",
    "        self.results_df = pd.DataFrame(columns=self.COLS)\n",
    "        \n",
    "    def get_results_df(self):\n",
    "        '''Get results in pandas.DataFrame.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pandas.DataFrame\n",
    "        '''\n",
    "        for result in self.results:\n",
    "            \n",
    "            row = []\n",
    "            if result.main_points:  \n",
    "                if isinstance(result.title, float):\n",
    "                    result.title = 'Title Unknown'\n",
    "\n",
    "                if isinstance(result.url, float):\n",
    "                    row.append(self.ARTICLE_HEADER.format(result.title))\n",
    "                else:\n",
    "                    row.append(\n",
    "                        self.ARTICLE_LINK_HEADER.format(\n",
    "                                result.url, result.title\n",
    "                        )\n",
    "                    )\n",
    "                \n",
    "                info = result.study_info\n",
    "                row.append(info.peer_reviewed)\n",
    "                # row.append(info.num_studies)\n",
    "                row.append(info.sample_size)\n",
    "                row.append(', '.join(info.study_designs))\n",
    "                row.append(self.get_article_mainpoints_text(result))\n",
    "            \n",
    "            row_df = pd.DataFrame([row], columns=self.COLS)\n",
    "            self.results_df = pd.concat([self.results_df, row_df], ignore_index=True)\n",
    "\n",
    "        return self.results_df\n",
    "    \n",
    "    def get_article_mainpoints_text(self, result):\n",
    "        '''Return text of main points within the article, in bullet format.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        search_result : SearchResult\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        str\n",
    "        '''\n",
    "        text = ''\n",
    "        for point in result.main_points:    \n",
    "            words = [\n",
    "                self.HIGHLIGHT.format(word) \n",
    "                # if word.replace(',', '') in result.keywords else word \n",
    "                if Summary.is_decimal_value_in_text(word) else word\n",
    "                for word in point.split()\n",
    "            ]\n",
    "\n",
    "            point = ' '.join(words)\n",
    "            text += '{} -- {} <br><br>'.format(self.SPACES, point)\n",
    "        return text\n",
    "\n",
    "    \n",
    "        \n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "SEARCH_SCORE_THRESHOLD = 10\n",
    "\n",
    "\n",
    "def get_n(bm25_model, keywords):\n",
    "    '''Get number of articles that pass threshold.\n",
    "\n",
    "    NOTE: counts only the articles in the `TOP_N_ARTICLES`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    bm25_model : rank_bm25.BM25Okapi\n",
    "        Ranking/scoring model trained on corpus dataset.\n",
    "    keywords : List[str]\n",
    "        Search query keywords.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        Number of similarity scores of `top_n` articles that pass threshold.\n",
    "    '''\n",
    "    return len(\n",
    "        [score for score in sorted(\n",
    "            bm25_model.get_scores(keywords), reverse=True\n",
    "        )[:TOP_N_ARTICLES] if score > SEARCH_SCORE_THRESHOLD]\n",
    "    )\n",
    "\n",
    "def get_search_results(search):\n",
    "    \n",
    "    global data\n",
    "    global num_pass_threshold\n",
    "    global all_keywords\n",
    "    \n",
    "    '''Get search results of search query.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    search : SearchQuery\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    List[SearchResult]\n",
    "    '''\n",
    "    data = pd.read_csv(\"E:\\\\COVID-app\\\\article_info.csv\")\n",
    "    \n",
    "    all_keywords = search.query_keywords + search.related_keywords\n",
    "    \n",
    "    bm25_model = load_model(\"E:\\\\COVID-app\\\\bm25_model\")\n",
    "    num_pass_threshold = get_n(bm25_model, all_keywords)\n",
    "\n",
    "    if num_pass_threshold == 0:\n",
    "        return []\n",
    "    else:\n",
    "        if num_pass_threshold != 0:\n",
    "\n",
    "            results_text = bm25_model.get_top_n(\n",
    "                all_keywords, data['text'], n = num_pass_threshold\n",
    "            )\n",
    "            results_title = bm25_model.get_top_n(\n",
    "                all_keywords, data['title_meta'], n =num_pass_threshold\n",
    "            )\n",
    "\n",
    "            results_url = bm25_model.get_top_n(\n",
    "                all_keywords, data['url'], n =num_pass_threshold\n",
    "            )\n",
    "\n",
    "            return [\n",
    "                SearchResult(\n",
    "                    title, text, url, all_keywords\n",
    "                ) for title, text, url in zip(results_title, results_text, results_url)\n",
    "            ]\n",
    "\n",
    "def get_query_results(query):\n",
    "    '''Get results of search query.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    query : str\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    ResultsHTMLText\n",
    "    '''\n",
    "    \n",
    "    #global keywords\n",
    "    \n",
    "    search_query = SearchQuery(query)\n",
    "    \n",
    "    keywords = search_query.query_keywords + search_query.related_keywords\n",
    "    display(HTML(f'<h3>Search Terms: {\", \".join(keywords)}</h3>'))\n",
    "\n",
    "    results = get_search_results(search_query)\n",
    "    # return ResultsHTMLText(results).get_results_text()\n",
    "    return ResultsDataFrame(results).get_results_df()\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "def print_answers(queries):\n",
    "    '''Print search results to each query.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    tasks : List[str]\n",
    "    '''\n",
    "    for query in queries:\n",
    "        display(HTML(f'<h2>{query:} \\n</h2>'))\n",
    "        final_result = get_query_results(query)\n",
    "\n",
    "        # display(HTML(final_result))\n",
    "        display(final_result.style)\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "insured-surface",
   "metadata": {},
   "source": [
    "# Search your query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "married-depth",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your question : corona virus\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h2>corona virus \n",
       "</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Search Terms: corona, pseudorabies, norwalk, coxsackie, varicella-zoster, bluetongue, encephalomyocarditis, arteritis, sindbis, papilloma, torque</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_ca80a45e_5d44_11eb_a0b7_54bf642dd5cc\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Title</th>        <th class=\"col_heading level0 col1\" >Article is peer reviewed</th>        <th class=\"col_heading level0 col2\" >Sample size of Article</th>        <th class=\"col_heading level0 col3\" >Study Design</th>        <th class=\"col_heading level0 col4\" >Main Points</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_ca80a45e_5d44_11eb_a0b7_54bf642dd5cclevel0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_ca80a45e_5d44_11eb_a0b7_54bf642dd5ccrow0_col0\" class=\"data row0 col0\" ><a href=\"https://doi.org/10.1016/j.jgg.2020.01.003\"> <i>Identification of potential cross-protective epitope between a new type of coronavirus (2019-nCoV) and severe acute respiratory syndrome virus</i></a><br></td>\n",
       "                        <td id=\"T_ca80a45e_5d44_11eb_a0b7_54bf642dd5ccrow0_col1\" class=\"data row0 col1\" >None</td>\n",
       "                        <td id=\"T_ca80a45e_5d44_11eb_a0b7_54bf642dd5ccrow0_col2\" class=\"data row0 col2\" >None</td>\n",
       "                        <td id=\"T_ca80a45e_5d44_11eb_a0b7_54bf642dd5ccrow0_col3\" class=\"data row0 col3\" ></td>\n",
       "                        <td id=\"T_ca80a45e_5d44_11eb_a0b7_54bf642dd5ccrow0_col4\" class=\"data row0 col4\" >&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp; -- Considering the default cutoff of <span style=\"background-color:#FFB6C1\">0.75</span> as antigenically similar (Qiu et al., 2018) , these results indicate the existence of potential CREs between 2019-nCoV and SARS virus. <br><br></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_ca80a45e_5d44_11eb_a0b7_54bf642dd5cclevel0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_ca80a45e_5d44_11eb_a0b7_54bf642dd5ccrow1_col0\" class=\"data row1 col0\" ><i>Title Unknown</i> <br></td>\n",
       "                        <td id=\"T_ca80a45e_5d44_11eb_a0b7_54bf642dd5ccrow1_col1\" class=\"data row1 col1\" >None</td>\n",
       "                        <td id=\"T_ca80a45e_5d44_11eb_a0b7_54bf642dd5ccrow1_col2\" class=\"data row1 col2\" >None</td>\n",
       "                        <td id=\"T_ca80a45e_5d44_11eb_a0b7_54bf642dd5ccrow1_col3\" class=\"data row1 col3\" ></td>\n",
       "                        <td id=\"T_ca80a45e_5d44_11eb_a0b7_54bf642dd5ccrow1_col4\" class=\"data row1 col4\" >&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp; -- In this review, we will discuss some of the recent findings related to the novel roles of ISGs in the PARP family in stress granule formation and stress responseinduced translational derepression of miRNA targets, involving PARP12, <span style=\"background-color:#FFB6C1\">ZAPL/PARP13.1,</span> and <span style=\"background-color:#FFB6C1\">ZAPS/PARP13.2.</span> <br><br></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_ca80a45e_5d44_11eb_a0b7_54bf642dd5cclevel0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_ca80a45e_5d44_11eb_a0b7_54bf642dd5ccrow2_col0\" class=\"data row2 col0\" ><a href=\"https://doi.org/10.1101/2020.02.26.20027797\"> <i>Relations of parameters for describing the epidemic of COVID―19 by the Kermack―McKendrick model</i></a><br></td>\n",
       "                        <td id=\"T_ca80a45e_5d44_11eb_a0b7_54bf642dd5ccrow2_col1\" class=\"data row2 col1\" >False</td>\n",
       "                        <td id=\"T_ca80a45e_5d44_11eb_a0b7_54bf642dd5ccrow2_col2\" class=\"data row2 col2\" >None</td>\n",
       "                        <td id=\"T_ca80a45e_5d44_11eb_a0b7_54bf642dd5ccrow2_col3\" class=\"data row2 col3\" ></td>\n",
       "                        <td id=\"T_ca80a45e_5d44_11eb_a0b7_54bf642dd5ccrow2_col4\" class=\"data row2 col4\" >&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp; -- The copyright holder for this (which was not peer-reviewed) is from <span style=\"background-color:#FFB6C1\">0.52</span> weeks, the time constant of the rising of the epidemic can be increased to <span style=\"background-color:#FFB6C1\">1.5</span> weeks in the model calculation, but the width of the epidemic in the model calculation was too wider than the real one as shown in Fig.6 . <br><br>&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp; -- Useful By applying the model, we found that the epidemic of influenza in Japan in 2019 was re-produced by the parameters;τ trans = <span style=\"background-color:#FFB6C1\">0.52</span> week and τ inf = 1 week and that τ grow observed in the early stage can be different from τ grow for re-producing the overall epidemic. <br><br></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_ca80a45e_5d44_11eb_a0b7_54bf642dd5cclevel0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_ca80a45e_5d44_11eb_a0b7_54bf642dd5ccrow3_col0\" class=\"data row3 col0\" ><a href=\"https://doi.org/10.1016/s0140-6736(20)30365-2\"> <i>What are the risks of COVID-19 infection in pregnant women?</i></a><br></td>\n",
       "                        <td id=\"T_ca80a45e_5d44_11eb_a0b7_54bf642dd5ccrow3_col1\" class=\"data row3 col1\" >None</td>\n",
       "                        <td id=\"T_ca80a45e_5d44_11eb_a0b7_54bf642dd5ccrow3_col2\" class=\"data row3 col2\" >None</td>\n",
       "                        <td id=\"T_ca80a45e_5d44_11eb_a0b7_54bf642dd5ccrow3_col3\" class=\"data row3 col3\" ></td>\n",
       "                        <td id=\"T_ca80a45e_5d44_11eb_a0b7_54bf642dd5ccrow3_col4\" class=\"data row3 col4\" >&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp; -- The number of people with novel coronavirus disease 2019 (COVID19) has risen above 75 000 globally, over <span style=\"background-color:#FFB6C1\">99%</span> of whom are in China, with more than 900 cases in 25 other countries as of Feb 20, 2020. <br><br></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_ca80a45e_5d44_11eb_a0b7_54bf642dd5cclevel0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_ca80a45e_5d44_11eb_a0b7_54bf642dd5ccrow4_col0\" class=\"data row4 col0\" ><a href=\"https://doi.org/10.1016/j.clae.2020.03.007\"> <i>Contact lens practice in the time of COVID-19</i></a><br></td>\n",
       "                        <td id=\"T_ca80a45e_5d44_11eb_a0b7_54bf642dd5ccrow4_col1\" class=\"data row4 col1\" >None</td>\n",
       "                        <td id=\"T_ca80a45e_5d44_11eb_a0b7_54bf642dd5ccrow4_col2\" class=\"data row4 col2\" >None</td>\n",
       "                        <td id=\"T_ca80a45e_5d44_11eb_a0b7_54bf642dd5ccrow4_col3\" class=\"data row4 col3\" ></td>\n",
       "                        <td id=\"T_ca80a45e_5d44_11eb_a0b7_54bf642dd5ccrow4_col4\" class=\"data row4 col4\" >&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp; -- Similarly in contact lens (CL) practice, the impact of outbreak is massive because CL practitioners are exposed to the infection and need to consider how they can play a role in preventing the transmission. <br><br>&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp; -- The droplets can make contact with the nose, mouth, eyes, or upper respiratory tract of another person through three main important routes (see Fig. 1 ) . <br><br>&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp; -- The second is a direct contact transmission as when two people shake their hands and the contaminated hand then touches a risk area on the second person. <br><br>&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp; -- Looking at available evidence in research papers, from the largest authorities in disease control and prevention around the world and from professional associations, there are at least 5 main areas of actions applicable in CL practice to minimise the transmission of COVID-19: patient management; personal protective equipment; disinfection of CL equipment and CL trial set; hands sanitisation; CL practitioner and staff monitoring. <br><br>&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp; -- In the case of a patient attending an appointment it is important to evaluate the risk that the patient may pose, such as patients who travelled to outbreak areas within 14 days, patients with upper respiratory tract infection (e.g. cough), and patients with conjunctivitis [9, 19, 21] . <br><br></td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1d513f47508>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = str(input(\"Enter your question : \")) \n",
    "queries = []\n",
    "queries.append(n)\n",
    "\n",
    "print_answers(queries)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
